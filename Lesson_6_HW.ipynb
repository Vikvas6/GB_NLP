{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести сравнение RNN, LSTM, GRU на датасете отзывов (из предыдущих занятий/материалов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "max_len = 40\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(\"отзывы за лето.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "exclude = set(punctuation)\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in exclude]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "data['text'] = data['Content'].apply(preprocess_text)\n",
    "data = data[data['Rating'] != 3]\n",
    "data['target'] = data['Rating'] > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>it just works</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>в целое удобноной приложениеиз минус хотеть сл...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>отлично весь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>стать зависать на 1 работа антивирус далёкий н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>очень удобно работать быстро</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date  \\\n",
       "0       5                                     It just works!  2017-08-14   \n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14   \n",
       "2       5                                        Отлично все  2017-08-14   \n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14   \n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14   \n",
       "\n",
       "                                                text  target  \n",
       "0                                      it just works       1  \n",
       "1  в целое удобноной приложениеиз минус хотеть сл...       1  \n",
       "2                                       отлично весь       1  \n",
       "3  стать зависать на 1 работа антивирус далёкий н...       1  \n",
       "4                       очень удобно работать быстро       1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = data['target'].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(data[\"text\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vikvas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['с',\n",
       " 'что',\n",
       " 'отлично',\n",
       " 'спасибо',\n",
       " 'хороший',\n",
       " 'нравиться',\n",
       " 'отличный',\n",
       " 'это',\n",
       " 'хорошо',\n",
       " 'телефон']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.asarray([text_to_sequence(text, max_len) for text in data[\"text\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, data['target'], test_size=0.2,\n",
    "                                                    random_state=13, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=max_words,\n",
    "              input_length=max_len,\n",
    "              output_dim=128,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1/28 [>.............................] - ETA: 0s - loss: 0.6840 - accuracy: 0.6133WARNING:tensorflow:From C:\\Users\\Vikvas\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/28 [=>............................] - ETA: 1s - loss: 0.6549 - accuracy: 0.7217WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0381s vs `on_train_batch_end` time: 0.0912s). Check your callbacks.\n",
      "28/28 [==============================] - 1s 48ms/step - loss: 0.4052 - accuracy: 0.8467 - val_loss: 0.3027 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2715 - accuracy: 0.8945 - val_loss: 0.2318 - val_accuracy: 0.8968\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2078 - accuracy: 0.9190 - val_loss: 0.2349 - val_accuracy: 0.9038\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1981 - accuracy: 0.9221\n",
      "\n",
      "\n",
      "Train score: 0.19807977974414825\n",
      "Train accuracy: 0.9221420288085938\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2299 - accuracy: 0.9129\n",
      "\n",
      "\n",
      "Test score: 0.22994816303253174\n",
      "Test accuracy: 0.9129114151000977\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9569694499005548"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=max_words,\n",
    "              input_length=max_len,\n",
    "              output_dim=128,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/28 [=>............................] - ETA: 28s - loss: 0.6909 - accuracy: 0.5615WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0839s vs `on_train_batch_end` time: 2.1131s). Check your callbacks.\n",
      "28/28 [==============================] - 4s 161ms/step - loss: 0.4567 - accuracy: 0.8261 - val_loss: 0.3049 - val_accuracy: 0.8487\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 2s 72ms/step - loss: 0.2766 - accuracy: 0.8866 - val_loss: 0.2240 - val_accuracy: 0.8981\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 2s 70ms/step - loss: 0.2069 - accuracy: 0.9140 - val_loss: 0.1877 - val_accuracy: 0.9127\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 2s 71ms/step - loss: 0.1659 - accuracy: 0.9335 - val_loss: 0.1714 - val_accuracy: 0.9304\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 2s 71ms/step - loss: 0.1470 - accuracy: 0.9440 - val_loss: 0.1746 - val_accuracy: 0.9285\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 19ms/step - loss: 0.1340 - accuracy: 0.9489\n",
      "\n",
      "\n",
      "Train score: 0.13404768705368042\n",
      "Train accuracy: 0.94891756772995\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1738 - accuracy: 0.9238\n",
      "\n",
      "\n",
      "Test score: 0.17375034093856812\n",
      "Test accuracy: 0.9237974882125854\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9622290578018258"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут я пробовал разные настройки LSTM - убирал Early_Stopping, менял настройку validation_split, немного менял число нейронов в слоях, добавлял новые слои, но только небольшое увеличение recurrent_dropout привело к увеличению метрики roc_auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=max_words,\n",
    "              input_length=max_len,\n",
    "              output_dim=128,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(LSTM(64, recurrent_dropout=0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/28 [=>............................] - ETA: 29s - loss: 0.6885 - accuracy: 0.6602WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0859s vs `on_train_batch_end` time: 2.1716s). Check your callbacks.\n",
      "28/28 [==============================] - 5s 185ms/step - loss: 0.4765 - accuracy: 0.8358 - val_loss: 0.3220 - val_accuracy: 0.8595\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.2818 - accuracy: 0.8875 - val_loss: 0.2291 - val_accuracy: 0.8918\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.2094 - accuracy: 0.9139 - val_loss: 0.1921 - val_accuracy: 0.9063\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.1704 - accuracy: 0.9321 - val_loss: 0.1796 - val_accuracy: 0.9222\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.1464 - accuracy: 0.9442 - val_loss: 0.1801 - val_accuracy: 0.9215\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 26ms/step - loss: 0.1350 - accuracy: 0.9471\n",
      "\n",
      "\n",
      "Train score: 0.1350240856409073\n",
      "Train accuracy: 0.9471452236175537\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 0.1791 - accuracy: 0.9263\n",
      "\n",
      "\n",
      "Test score: 0.17906466126441956\n",
      "Test accuracy: 0.9263291358947754\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629796538561317"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=max_words,\n",
    "              input_length=max_len,\n",
    "              output_dim=128,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/28 [=>............................] - ETA: 32s - loss: 0.7010 - accuracy: 0.3555WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0752s vs `on_train_batch_end` time: 2.3946s). Check your callbacks.\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.4948 - accuracy: 0.8113 - val_loss: 0.3313 - val_accuracy: 0.8481\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 0.2894 - accuracy: 0.8787 - val_loss: 0.2349 - val_accuracy: 0.8924\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 2s 74ms/step - loss: 0.2135 - accuracy: 0.9111 - val_loss: 0.1900 - val_accuracy: 0.9070\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 0.1714 - accuracy: 0.9304 - val_loss: 0.1761 - val_accuracy: 0.9253\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 2s 77ms/step - loss: 0.1471 - accuracy: 0.9439 - val_loss: 0.1735 - val_accuracy: 0.9285\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 0.1325 - accuracy: 0.9519 - val_loss: 0.1820 - val_accuracy: 0.9285\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 22ms/step - loss: 0.1303 - accuracy: 0.9529\n",
      "\n",
      "\n",
      "Train score: 0.13027864694595337\n",
      "Train accuracy: 0.9529054164886475\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Train score:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 0.1842 - accuracy: 0.9233\n",
      "\n",
      "\n",
      "Test score: 0.1841762214899063\n",
      "Test accuracy: 0.9232911467552185\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957793178420981"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге среди реккурентных архитектур LSTM показала лучший резульат, хоть и обучалась несколько дольше. Вот только в предыдущем задании на свёрточном слое я получил результат лучше ~0.9668."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
